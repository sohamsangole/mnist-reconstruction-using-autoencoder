{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Soham Sangole\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 6.97k/6.97k [00:00<00:00, 7.05MB/s]\n",
      "Downloading data: 100%|██████████| 15.6M/15.6M [00:07<00:00, 2.09MB/s]\n",
      "Downloading data: 100%|██████████| 2.60M/2.60M [00:00<00:00, 2.75MB/s]\n",
      "Generating train split: 100%|██████████| 60000/60000 [00:00<00:00, 82503.65 examples/s]\n",
      "Generating test split: 100%|██████████| 10000/10000 [00:00<00:00, 100974.62 examples/s]\n"
     ]
    }
   ],
   "source": [
    "ds = load_dataset(\"ylecun/mnist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imageAtIndex(index):\n",
    "    print(ds['train']['image'][index], ds['train']['label'][index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28 at 0x22A861AD310> 4\n"
     ]
    }
   ],
   "source": [
    "imageAtIndex(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder,self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(784,128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128,64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64,32),\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(32,64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 784),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoEncoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=784, out_features=128, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Linear(in_features=64, out_features=32, bias=True)\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=32, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=64, out_features=128, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=128, out_features=784, bias=True)\n",
       "    (5): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 0.025724028729721127\n",
      "Epoch [2/20], Loss: 0.018425951996253572\n",
      "Epoch [3/20], Loss: 0.016289797009700367\n",
      "Epoch [4/20], Loss: 0.015077385172684444\n",
      "Epoch [5/20], Loss: 0.014452993810085657\n",
      "Epoch [6/20], Loss: 0.014072945572167131\n",
      "Epoch [7/20], Loss: 0.013792522682270889\n",
      "Epoch [8/20], Loss: 0.013620988921096432\n",
      "Epoch [9/20], Loss: 0.013479727258562344\n",
      "Epoch [10/20], Loss: 0.013343840716884006\n",
      "Epoch [11/20], Loss: 0.01325978291054489\n",
      "Epoch [12/20], Loss: 0.013176993361789695\n",
      "Epoch [13/20], Loss: 0.01310378706776731\n",
      "Epoch [14/20], Loss: 0.013064102615062924\n",
      "Epoch [15/20], Loss: 0.012985477360788112\n",
      "Epoch [16/20], Loss: 0.012945383848281927\n",
      "Epoch [17/20], Loss: 0.012892594518507636\n",
      "Epoch [18/20], Loss: 0.0128848624984336\n",
      "Epoch [19/20], Loss: 0.012869797686257517\n",
      "Epoch [20/20], Loss: 0.012820577094336235\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train() \n",
    "    train_loss = 0.0 \n",
    "    \n",
    "    for batch in ds[\"train\"]:  \n",
    "        inputs = transform(batch[\"image\"]).unsqueeze(0).float() \n",
    "        inputs = inputs.to(device) \n",
    "        \n",
    "        inputs_flat = inputs.view(inputs.size(0), -1)\n",
    "        \n",
    "        outputs = model(inputs_flat)\n",
    "        \n",
    "        outputs_reshaped = outputs.view(inputs.size(0), 1, 28, 28)\n",
    "        \n",
    "        loss = criterion(outputs_reshaped, inputs)\n",
    "        \n",
    "        optimizer.zero_grad()  \n",
    "        loss.backward()        \n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item() \n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {train_loss / len(ds['train'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"autoencoder.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_reconstruction(model, dataset):\n",
    "    model.eval() \n",
    "    with torch.no_grad():\n",
    "        for batch in dataset[\"test\"]:\n",
    "            inputs = transform(batch[\"image\"]).unsqueeze(0).float().to(device)\n",
    "            inputs_flat = inputs.view(inputs.size(0), -1)\n",
    "            \n",
    "            outputs = model(inputs_flat)\n",
    "            outputs_reshaped = outputs.view(inputs.size(0), 1, 28, 28)\n",
    "            \n",
    "            fig, axs = plt.subplots(1, 2)\n",
    "            axs[0].imshow(inputs.cpu().squeeze(), cmap=\"gray\")\n",
    "            axs[0].set_title(\"Original\")\n",
    "            \n",
    "            axs[1].imshow(outputs_reshaped.cpu().squeeze(), cmap=\"gray\")\n",
    "            axs[1].set_title(\"Reconstructed\")\n",
    "            \n",
    "            plt.show()\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoEncoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=784, out_features=128, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Linear(in_features=64, out_features=32, bias=True)\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=32, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=64, out_features=128, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=128, out_features=784, bias=True)\n",
       "    (5): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"autoencoder.pth\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
